{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/timeseries/timeseries_weather_forecasting/\n",
    "# https://www.researchgate.net/publication/343250071_Recognizing_Emotions_Evoked_by_Music_using_CNN-LSTM_Networks_on_EEG_signals\n",
    "import pandas as pd\n",
    "from utils import get_dfs, extract_classes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from model import run_model\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_around_event(df_filtered, events, before=0, after=5):\n",
    "    df_output = None\n",
    "    for idx in events.loc[events.label=='start'].index:\n",
    "        start = pd.to_datetime(idx) + timedelta(seconds=before)\n",
    "        end = pd.to_datetime(idx) + timedelta(seconds=after)\n",
    "        if df_output is None:\n",
    "            df_output = df_filtered.loc[(start<=pd.to_datetime(df_filtered.index)) & (pd.to_datetime(df_filtered.index)<=end)]\n",
    "        else:\n",
    "            df_output = pd.concat([df_output, df_filtered.loc[(start<=pd.to_datetime(df_filtered.index)) & (pd.to_datetime(df_filtered.index)<=end)]])\n",
    "        df_output = df_output.drop_duplicates().copy()\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_file_path = [\n",
    "    \"../data/20221029-171117.hdf5\",\n",
    "    \"../data/20221029-192231.hdf5\",\n",
    "    \"../data/20221029-200201.hdf5\",\n",
    "    \"../data/20221029-202757.hdf5\",\n",
    "    \"../data/othmane_assis_EEG_20221029-231521.hdf5\"\n",
    "]\n",
    "\n",
    "result_filtered = None\n",
    "result_events = None\n",
    "\n",
    "for path in hdf_file_path:\n",
    "    _, df_events, df_filtered, _ = get_dfs(path)\n",
    "    df_filtered = select_data_around_event(df_filtered, df_events, before=-2, after=12)\n",
    "    if result_filtered is None:\n",
    "        result_filtered = df_filtered\n",
    "    else:\n",
    "        result_filtered = pd.concat([result_filtered, df_filtered])\n",
    "\n",
    "    if result_events is None:\n",
    "        result_events = df_events\n",
    "    else:\n",
    "        result_events = pd.concat([result_events, df_events])\n",
    "# Clean events to have only 3 classes\n",
    "result_events.replace('\"repos\"', 'neutral', inplace=True)\n",
    "result_events.replace(['\"calme\"', '\"lent\"'], 'positive', inplace=True)\n",
    "result_events.replace(['\"rapide\"', '\"agite\"'], 'negative', inplace=True)\n",
    "result_events = result_events[result_events.data != '\"fin\"']\n",
    "result_events = result_events[result_events.data != '\"calme\"']\n",
    "result_events = result_events[result_events.data != '\"agite\"']\n",
    "result_events = result_events[result_events.data != '\"interuption\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ts_for_training(ts_df, event_df):\n",
    "    df_lag = ts_df.copy()\n",
    "    for i in range(1, 100):\n",
    "        df_lag = df_lag.merge(ts_df.shift(i), how='inner', left_index=True, right_index=True, suffixes=('',f'_{i:02d}'))\n",
    "    ts_df = df_lag.dropna().copy()\n",
    "    del df_lag\n",
    "\n",
    "    res = None\n",
    "    classes = extract_classes(event_df)\n",
    "    tmp_event_df = event_df.copy()\n",
    "    for c in range(len(classes)):\n",
    "        start_events = event_df.loc[(event_df.data == classes[c])]\n",
    "        ref_start_date = start_events.index[0]\n",
    "        start = event_df.loc[(event_df.data == classes[c]) & (event_df.label == 'start')].index[0]\n",
    "        end = event_df.loc[(event_df.data == classes[c]) & (event_df.label == 'stop')].index\n",
    "\n",
    "        if len(end) == 0:\n",
    "            end = ts_df.index[-1]\n",
    "        else:\n",
    "            end = end[0]\n",
    "\n",
    "        if c < len(classes) - 2:\n",
    "            tmp_event_df = tmp_event_df.drop(tmp_event_df.index[0])\n",
    "\n",
    "        current = ts_df[start:end].head(5000)\n",
    "        current['class'] = classes[c].replace('\"', '')\n",
    "        if res is None:\n",
    "            res = current\n",
    "        else:\n",
    "            res = pd.concat([res, current])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = prepare_ts_for_training(df_filtered, df_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fpz</th>\n",
       "      <th>Fpz_01</th>\n",
       "      <th>Fpz_02</th>\n",
       "      <th>Fpz_03</th>\n",
       "      <th>Fpz_04</th>\n",
       "      <th>Fpz_05</th>\n",
       "      <th>Fpz_06</th>\n",
       "      <th>Fpz_07</th>\n",
       "      <th>Fpz_08</th>\n",
       "      <th>Fpz_09</th>\n",
       "      <th>...</th>\n",
       "      <th>Fpz_91</th>\n",
       "      <th>Fpz_92</th>\n",
       "      <th>Fpz_93</th>\n",
       "      <th>Fpz_94</th>\n",
       "      <th>Fpz_95</th>\n",
       "      <th>Fpz_96</th>\n",
       "      <th>Fpz_97</th>\n",
       "      <th>Fpz_98</th>\n",
       "      <th>Fpz_99</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:16:35.221257</th>\n",
       "      <td>-2.009272</td>\n",
       "      <td>-2.830380</td>\n",
       "      <td>0.678026</td>\n",
       "      <td>3.171745</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-1.959629</td>\n",
       "      <td>-0.344298</td>\n",
       "      <td>-0.569524</td>\n",
       "      <td>-0.715359</td>\n",
       "      <td>1.636246</td>\n",
       "      <td>...</td>\n",
       "      <td>4.751460</td>\n",
       "      <td>5.493750</td>\n",
       "      <td>5.991572</td>\n",
       "      <td>4.044888</td>\n",
       "      <td>2.897071</td>\n",
       "      <td>3.491017</td>\n",
       "      <td>4.123820</td>\n",
       "      <td>5.224463</td>\n",
       "      <td>5.655671</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:16:35.231257</th>\n",
       "      <td>-1.542927</td>\n",
       "      <td>-2.009272</td>\n",
       "      <td>-2.830380</td>\n",
       "      <td>0.678026</td>\n",
       "      <td>3.171745</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-1.959629</td>\n",
       "      <td>-0.344298</td>\n",
       "      <td>-0.569524</td>\n",
       "      <td>-0.715359</td>\n",
       "      <td>...</td>\n",
       "      <td>6.356289</td>\n",
       "      <td>4.751460</td>\n",
       "      <td>5.493750</td>\n",
       "      <td>5.991572</td>\n",
       "      <td>4.044888</td>\n",
       "      <td>2.897071</td>\n",
       "      <td>3.491017</td>\n",
       "      <td>4.123820</td>\n",
       "      <td>5.224463</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:16:35.241257</th>\n",
       "      <td>-2.104169</td>\n",
       "      <td>-1.542927</td>\n",
       "      <td>-2.009272</td>\n",
       "      <td>-2.830380</td>\n",
       "      <td>0.678026</td>\n",
       "      <td>3.171745</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-1.959629</td>\n",
       "      <td>-0.344298</td>\n",
       "      <td>-0.569524</td>\n",
       "      <td>...</td>\n",
       "      <td>8.057441</td>\n",
       "      <td>6.356289</td>\n",
       "      <td>4.751460</td>\n",
       "      <td>5.493750</td>\n",
       "      <td>5.991572</td>\n",
       "      <td>4.044888</td>\n",
       "      <td>2.897071</td>\n",
       "      <td>3.491017</td>\n",
       "      <td>4.123820</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:16:35.251257</th>\n",
       "      <td>-3.855607</td>\n",
       "      <td>-2.104169</td>\n",
       "      <td>-1.542927</td>\n",
       "      <td>-2.009272</td>\n",
       "      <td>-2.830380</td>\n",
       "      <td>0.678026</td>\n",
       "      <td>3.171745</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-1.959629</td>\n",
       "      <td>-0.344298</td>\n",
       "      <td>...</td>\n",
       "      <td>6.376958</td>\n",
       "      <td>8.057441</td>\n",
       "      <td>6.356289</td>\n",
       "      <td>4.751460</td>\n",
       "      <td>5.493750</td>\n",
       "      <td>5.991572</td>\n",
       "      <td>4.044888</td>\n",
       "      <td>2.897071</td>\n",
       "      <td>3.491017</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:16:35.261257</th>\n",
       "      <td>-7.218886</td>\n",
       "      <td>-3.855607</td>\n",
       "      <td>-2.104169</td>\n",
       "      <td>-1.542927</td>\n",
       "      <td>-2.009272</td>\n",
       "      <td>-2.830380</td>\n",
       "      <td>0.678026</td>\n",
       "      <td>3.171745</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-1.959629</td>\n",
       "      <td>...</td>\n",
       "      <td>4.146209</td>\n",
       "      <td>6.376958</td>\n",
       "      <td>8.057441</td>\n",
       "      <td>6.356289</td>\n",
       "      <td>4.751460</td>\n",
       "      <td>5.493750</td>\n",
       "      <td>5.991572</td>\n",
       "      <td>4.044888</td>\n",
       "      <td>2.897071</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:17:41.211257</th>\n",
       "      <td>-9.482399</td>\n",
       "      <td>-11.330754</td>\n",
       "      <td>-8.497556</td>\n",
       "      <td>-5.703738</td>\n",
       "      <td>-4.603766</td>\n",
       "      <td>-1.873417</td>\n",
       "      <td>-0.038962</td>\n",
       "      <td>-1.759661</td>\n",
       "      <td>-2.256699</td>\n",
       "      <td>1.349223</td>\n",
       "      <td>...</td>\n",
       "      <td>1.845712</td>\n",
       "      <td>6.299041</td>\n",
       "      <td>6.682110</td>\n",
       "      <td>1.837155</td>\n",
       "      <td>-0.309724</td>\n",
       "      <td>-1.546288</td>\n",
       "      <td>-6.953978</td>\n",
       "      <td>-8.705737</td>\n",
       "      <td>-3.774636</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:17:41.221257</th>\n",
       "      <td>-7.837791</td>\n",
       "      <td>-9.482399</td>\n",
       "      <td>-11.330754</td>\n",
       "      <td>-8.497556</td>\n",
       "      <td>-5.703738</td>\n",
       "      <td>-4.603766</td>\n",
       "      <td>-1.873417</td>\n",
       "      <td>-0.038962</td>\n",
       "      <td>-1.759661</td>\n",
       "      <td>-2.256699</td>\n",
       "      <td>...</td>\n",
       "      <td>2.581853</td>\n",
       "      <td>1.845712</td>\n",
       "      <td>6.299041</td>\n",
       "      <td>6.682110</td>\n",
       "      <td>1.837155</td>\n",
       "      <td>-0.309724</td>\n",
       "      <td>-1.546288</td>\n",
       "      <td>-6.953978</td>\n",
       "      <td>-8.705737</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:17:41.231257</th>\n",
       "      <td>-8.989871</td>\n",
       "      <td>-7.837791</td>\n",
       "      <td>-9.482399</td>\n",
       "      <td>-11.330754</td>\n",
       "      <td>-8.497556</td>\n",
       "      <td>-5.703738</td>\n",
       "      <td>-4.603766</td>\n",
       "      <td>-1.873417</td>\n",
       "      <td>-0.038962</td>\n",
       "      <td>-1.759661</td>\n",
       "      <td>...</td>\n",
       "      <td>4.786506</td>\n",
       "      <td>2.581853</td>\n",
       "      <td>1.845712</td>\n",
       "      <td>6.299041</td>\n",
       "      <td>6.682110</td>\n",
       "      <td>1.837155</td>\n",
       "      <td>-0.309724</td>\n",
       "      <td>-1.546288</td>\n",
       "      <td>-6.953978</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:17:41.241257</th>\n",
       "      <td>-8.440569</td>\n",
       "      <td>-8.989871</td>\n",
       "      <td>-7.837791</td>\n",
       "      <td>-9.482399</td>\n",
       "      <td>-11.330754</td>\n",
       "      <td>-8.497556</td>\n",
       "      <td>-5.703738</td>\n",
       "      <td>-4.603766</td>\n",
       "      <td>-1.873417</td>\n",
       "      <td>-0.038962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832803</td>\n",
       "      <td>4.786506</td>\n",
       "      <td>2.581853</td>\n",
       "      <td>1.845712</td>\n",
       "      <td>6.299041</td>\n",
       "      <td>6.682110</td>\n",
       "      <td>1.837155</td>\n",
       "      <td>-0.309724</td>\n",
       "      <td>-1.546288</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:17:41.251257</th>\n",
       "      <td>-7.015670</td>\n",
       "      <td>-8.440569</td>\n",
       "      <td>-8.989871</td>\n",
       "      <td>-7.837791</td>\n",
       "      <td>-9.482399</td>\n",
       "      <td>-11.330754</td>\n",
       "      <td>-8.497556</td>\n",
       "      <td>-5.703738</td>\n",
       "      <td>-4.603766</td>\n",
       "      <td>-1.873417</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.934549</td>\n",
       "      <td>0.832803</td>\n",
       "      <td>4.786506</td>\n",
       "      <td>2.581853</td>\n",
       "      <td>1.845712</td>\n",
       "      <td>6.299041</td>\n",
       "      <td>6.682110</td>\n",
       "      <td>1.837155</td>\n",
       "      <td>-0.309724</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Fpz     Fpz_01     Fpz_02     Fpz_03  \\\n",
       "2022-10-29 23:16:35.221257 -2.009272  -2.830380   0.678026   3.171745   \n",
       "2022-10-29 23:16:35.231257 -1.542927  -2.009272  -2.830380   0.678026   \n",
       "2022-10-29 23:16:35.241257 -2.104169  -1.542927  -2.009272  -2.830380   \n",
       "2022-10-29 23:16:35.251257 -3.855607  -2.104169  -1.542927  -2.009272   \n",
       "2022-10-29 23:16:35.261257 -7.218886  -3.855607  -2.104169  -1.542927   \n",
       "...                              ...        ...        ...        ...   \n",
       "2022-10-29 23:17:41.211257 -9.482399 -11.330754  -8.497556  -5.703738   \n",
       "2022-10-29 23:17:41.221257 -7.837791  -9.482399 -11.330754  -8.497556   \n",
       "2022-10-29 23:17:41.231257 -8.989871  -7.837791  -9.482399 -11.330754   \n",
       "2022-10-29 23:17:41.241257 -8.440569  -8.989871  -7.837791  -9.482399   \n",
       "2022-10-29 23:17:41.251257 -7.015670  -8.440569  -8.989871  -7.837791   \n",
       "\n",
       "                               Fpz_04     Fpz_05    Fpz_06    Fpz_07  \\\n",
       "2022-10-29 23:16:35.221257  -0.076711  -1.959629 -0.344298 -0.569524   \n",
       "2022-10-29 23:16:35.231257   3.171745  -0.076711 -1.959629 -0.344298   \n",
       "2022-10-29 23:16:35.241257   0.678026   3.171745 -0.076711 -1.959629   \n",
       "2022-10-29 23:16:35.251257  -2.830380   0.678026  3.171745 -0.076711   \n",
       "2022-10-29 23:16:35.261257  -2.009272  -2.830380  0.678026  3.171745   \n",
       "...                               ...        ...       ...       ...   \n",
       "2022-10-29 23:17:41.211257  -4.603766  -1.873417 -0.038962 -1.759661   \n",
       "2022-10-29 23:17:41.221257  -5.703738  -4.603766 -1.873417 -0.038962   \n",
       "2022-10-29 23:17:41.231257  -8.497556  -5.703738 -4.603766 -1.873417   \n",
       "2022-10-29 23:17:41.241257 -11.330754  -8.497556 -5.703738 -4.603766   \n",
       "2022-10-29 23:17:41.251257  -9.482399 -11.330754 -8.497556 -5.703738   \n",
       "\n",
       "                              Fpz_08    Fpz_09  ...    Fpz_91    Fpz_92  \\\n",
       "2022-10-29 23:16:35.221257 -0.715359  1.636246  ...  4.751460  5.493750   \n",
       "2022-10-29 23:16:35.231257 -0.569524 -0.715359  ...  6.356289  4.751460   \n",
       "2022-10-29 23:16:35.241257 -0.344298 -0.569524  ...  8.057441  6.356289   \n",
       "2022-10-29 23:16:35.251257 -1.959629 -0.344298  ...  6.376958  8.057441   \n",
       "2022-10-29 23:16:35.261257 -0.076711 -1.959629  ...  4.146209  6.376958   \n",
       "...                              ...       ...  ...       ...       ...   \n",
       "2022-10-29 23:17:41.211257 -2.256699  1.349223  ...  1.845712  6.299041   \n",
       "2022-10-29 23:17:41.221257 -1.759661 -2.256699  ...  2.581853  1.845712   \n",
       "2022-10-29 23:17:41.231257 -0.038962 -1.759661  ...  4.786506  2.581853   \n",
       "2022-10-29 23:17:41.241257 -1.873417 -0.038962  ...  0.832803  4.786506   \n",
       "2022-10-29 23:17:41.251257 -4.603766 -1.873417  ... -0.934549  0.832803   \n",
       "\n",
       "                              Fpz_93    Fpz_94    Fpz_95    Fpz_96    Fpz_97  \\\n",
       "2022-10-29 23:16:35.221257  5.991572  4.044888  2.897071  3.491017  4.123820   \n",
       "2022-10-29 23:16:35.231257  5.493750  5.991572  4.044888  2.897071  3.491017   \n",
       "2022-10-29 23:16:35.241257  4.751460  5.493750  5.991572  4.044888  2.897071   \n",
       "2022-10-29 23:16:35.251257  6.356289  4.751460  5.493750  5.991572  4.044888   \n",
       "2022-10-29 23:16:35.261257  8.057441  6.356289  4.751460  5.493750  5.991572   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "2022-10-29 23:17:41.211257  6.682110  1.837155 -0.309724 -1.546288 -6.953978   \n",
       "2022-10-29 23:17:41.221257  6.299041  6.682110  1.837155 -0.309724 -1.546288   \n",
       "2022-10-29 23:17:41.231257  1.845712  6.299041  6.682110  1.837155 -0.309724   \n",
       "2022-10-29 23:17:41.241257  2.581853  1.845712  6.299041  6.682110  1.837155   \n",
       "2022-10-29 23:17:41.251257  4.786506  2.581853  1.845712  6.299041  6.682110   \n",
       "\n",
       "                              Fpz_98    Fpz_99  class  \n",
       "2022-10-29 23:16:35.221257  5.224463  5.655671  repos  \n",
       "2022-10-29 23:16:35.231257  4.123820  5.224463  repos  \n",
       "2022-10-29 23:16:35.241257  3.491017  4.123820  repos  \n",
       "2022-10-29 23:16:35.251257  2.897071  3.491017  repos  \n",
       "2022-10-29 23:16:35.261257  4.044888  2.897071  repos  \n",
       "...                              ...       ...    ...  \n",
       "2022-10-29 23:17:41.211257 -8.705737 -3.774636  repos  \n",
       "2022-10-29 23:17:41.221257 -6.953978 -8.705737  repos  \n",
       "2022-10-29 23:17:41.231257 -1.546288 -6.953978  repos  \n",
       "2022-10-29 23:17:41.241257 -0.309724 -1.546288  repos  \n",
       "2022-10-29 23:17:41.251257  1.837155 -0.309724  repos  \n",
       "\n",
       "[100000 rows x 101 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.715\n",
    "train_split = int(split_fraction * int(final_df.shape[0]))\n",
    "step = 100\n",
    "\n",
    "past = 1000\n",
    "future = 300\n",
    "learning_rate = 0.001\n",
    "batch_size = 1500\n",
    "epochs = 10\n",
    "\n",
    "start = past + future\n",
    "end = start + train_split\n",
    "\n",
    "\n",
    "def normalize(data, train_split):\n",
    "    data_mean = data[:train_split].mean(axis=0)\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "    return (data - data_mean) / data_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ds():\n",
    "    feature_keys = final_df.columns\n",
    "    print(feature_keys)\n",
    "    selected_features = [feature_keys[i] for i in range(len(feature_keys))]\n",
    "    features = final_df[selected_features]\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    features['class'] = le.fit_transform(features['class'])\n",
    "    \n",
    "    features = normalize(features.values, train_split)\n",
    "    features = pd.DataFrame(features)\n",
    "    features[features.columns[-1]] = le.fit_transform(final_df['class'])\n",
    "\n",
    "    train_data = features.loc[0 : train_split - 1]\n",
    "    val_data = features.loc[train_split:]\n",
    "\n",
    "\n",
    "    start = past + future\n",
    "    end = start + train_split\n",
    "\n",
    "    x_train = train_data[[i for i in range(len(feature_keys) - 1)]].values\n",
    "    y_train = features.iloc[start:end][features.columns[-1]]\n",
    "\n",
    "    sequence_length = int(past / step)\n",
    "\n",
    "    dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        sequence_length=sequence_length,\n",
    "        sampling_rate=step,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    sequence_length = int(past / step)\n",
    "\n",
    "\n",
    "    x_end = len(val_data) - past - future\n",
    "    label_start = train_split + past + future\n",
    "    x_val = val_data.iloc[:x_end][[i for i in range(len(feature_keys) - 1)]].values\n",
    "    y_val = features.iloc[label_start:][features.columns[-1]]\n",
    "    # display(x_val.shape)\n",
    "    dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,)\n",
    "    \n",
    "    return dataset_train, dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Fpz', 'Fpz_01', 'Fpz_02', 'Fpz_03', 'Fpz_04', 'Fpz_05', 'Fpz_06',\n",
      "       'Fpz_07', 'Fpz_08', 'Fpz_09',\n",
      "       ...\n",
      "       'Fpz_91', 'Fpz_92', 'Fpz_93', 'Fpz_94', 'Fpz_95', 'Fpz_96', 'Fpz_97',\n",
      "       'Fpz_98', 'Fpz_99', 'class'],\n",
      "      dtype='object', length=101)\n",
      "Input shape: (1500, 10, 100)\n",
      "Target shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_val = load_ds()\n",
    "\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10, 100)]         0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 2, 16)             192016    \n",
      "                                                                 \n",
      " re_lu_11 (ReLU)             (None, 2, 16)             0         \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 1, 16)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 1, 32)             1568      \n",
      "                                                                 \n",
      " re_lu_12 (ReLU)             (None, 1, 32)             0         \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 1, 80)             7760      \n",
      "                                                                 \n",
      " re_lu_13 (ReLU)             (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 1, 80)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 1, 80)             19280     \n",
      "                                                                 \n",
      " re_lu_14 (ReLU)             (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 1, 80)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 1, 80)             19280     \n",
      "                                                                 \n",
      " re_lu_15 (ReLU)             (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 1, 80)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 1, 80)             19280     \n",
      "                                                                 \n",
      " re_lu_16 (ReLU)             (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 1, 80)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 1, 80)             19280     \n",
      "                                                                 \n",
      " re_lu_17 (ReLU)             (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 1, 80)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 1, 80)             19280     \n",
      "                                                                 \n",
      " re_lu_18 (ReLU)             (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 1, 80)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 1, 128)            107008    \n",
      "                                                                 \n",
      " re_lu_19 (ReLU)             (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " re_lu_20 (ReLU)             (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " re_lu_21 (ReLU)             (None, 1, 128)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 3)              387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 668,307\n",
      "Trainable params: 668,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 21s 291ms/step - loss: 1.0980 - accuracy: 0.3858 - val_loss: 1.0965 - val_accuracy: 0.3340\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 11s 229ms/step - loss: 1.0948 - accuracy: 0.4071 - val_loss: 1.0954 - val_accuracy: 0.3340\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 9s 189ms/step - loss: 1.0923 - accuracy: 0.4071 - val_loss: 1.0945 - val_accuracy: 0.3340\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 9s 196ms/step - loss: 1.0900 - accuracy: 0.4071 - val_loss: 1.0938 - val_accuracy: 0.3340\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 9s 195ms/step - loss: 1.0878 - accuracy: 0.4071 - val_loss: 1.0934 - val_accuracy: 0.3340\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 9s 180ms/step - loss: 1.0859 - accuracy: 0.4071 - val_loss: 1.0932 - val_accuracy: 0.3340\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 9s 191ms/step - loss: 1.0845 - accuracy: 0.4071 - val_loss: 1.0931 - val_accuracy: 0.3340\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 11s 222ms/step - loss: 1.0837 - accuracy: 0.4071 - val_loss: 1.0917 - val_accuracy: 0.3340\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 10s 205ms/step - loss: 1.0815 - accuracy: 0.4071 - val_loss: 1.0865 - val_accuracy: 0.3340\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 11s 224ms/step - loss: 1.0774 - accuracy: 0.4071 - val_loss: 1.0556 - val_accuracy: 0.3340\n"
     ]
    }
   ],
   "source": [
    "m = run_model(dataset_train, dataset_val, inputs, num_classes=3, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9ed0ad7719f06f089edc3238a8d86e962d4ca50119a2518cf9af3ef9ae01f6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
