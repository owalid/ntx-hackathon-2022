{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/timeseries/timeseries_weather_forecasting/\n",
    "# https://www.researchgate.net/publication/343250071_Recognizing_Emotions_Evoked_by_Music_using_CNN-LSTM_Networks_on_EEG_signals\n",
    "import pandas as pd\n",
    "from utils import get_dfs, extract_classes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from model import run_model\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_file_path = [\n",
    "    \"../data/20221029-171117.hdf5\",\n",
    "    \"../data/20221029-192231.hdf5\",\n",
    "    \"../data/20221029-200201.hdf5\",\n",
    "    \"../data/20221029-202757.hdf5\",\n",
    "    \"../data/othmane_assis_EEG_20221029-231521.hdf5\"\n",
    "]\n",
    "\n",
    "result_filtered = None\n",
    "result_events = None\n",
    "\n",
    "for path in hdf_file_path:\n",
    "    _, df_events, df_filtered, _ = get_dfs(path)\n",
    "    if result_filtered is None:\n",
    "        result_filtered = df_filtered\n",
    "    else:\n",
    "        result_filtered = pd.concat([result_filtered, df_filtered])\n",
    "\n",
    "    if result_events is None:\n",
    "        result_events = df_events\n",
    "    else:\n",
    "        result_events = pd.concat([result_events, df_events])\n",
    "# Clean events to have only 3 classes\n",
    "result_events.replace('\"repos\"', 'neutral', inplace=True)\n",
    "result_events.replace(['\"calme\"', '\"lent\"'], 'positive', inplace=True)\n",
    "result_events.replace(['\"rapide\"', '\"agite\"'], 'negative', inplace=True)\n",
    "result_events = result_events[result_events.data != '\"fin\"']\n",
    "result_events = result_events[result_events.data != '\"calme\"']\n",
    "result_events = result_events[result_events.data != '\"agite\"']\n",
    "result_events = result_events[result_events.data != '\"interuption\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ts_for_training(ts_df, event_df):\n",
    "    df_lag = ts_df.copy()\n",
    "    for i in range(1, 100):\n",
    "        df_lag = df_lag.merge(ts_df.shift(i), how='inner', left_index=True, right_index=True, suffixes=('',f'_{i:02d}'))\n",
    "    ts_df = df_lag.dropna().copy()\n",
    "    del df_lag\n",
    "\n",
    "    res = None\n",
    "    classes = extract_classes(event_df)\n",
    "    tmp_event_df = event_df.copy()\n",
    "    for c in range(len(classes)):\n",
    "        start_events = event_df.loc[(event_df.data == classes[c])]\n",
    "        ref_start_date = start_events.index[0]\n",
    "        start = event_df.loc[(event_df.data == classes[c]) & (event_df.label == 'start')].index[0]\n",
    "        end = event_df.loc[(event_df.data == classes[c]) & (event_df.label == 'stop')].index\n",
    "\n",
    "        if len(end) == 0:\n",
    "            end = ts_df.index[-1]\n",
    "        else:\n",
    "            end = end[0]\n",
    "\n",
    "        if c < len(classes) - 2:\n",
    "            tmp_event_df = tmp_event_df.drop(tmp_event_df.index[0])\n",
    "\n",
    "        current = ts_df[start:end].head(5000)\n",
    "        current['class'] = classes[c].replace('\"', '')\n",
    "        if res is None:\n",
    "            res = current\n",
    "        else:\n",
    "            res = pd.concat([res, current])\n",
    "    # res['date'] = res.index\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = prepare_ts_for_training(df_filtered, df_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fpz</th>\n",
       "      <th>Fpz_01</th>\n",
       "      <th>Fpz_02</th>\n",
       "      <th>Fpz_03</th>\n",
       "      <th>Fpz_04</th>\n",
       "      <th>Fpz_05</th>\n",
       "      <th>Fpz_06</th>\n",
       "      <th>Fpz_07</th>\n",
       "      <th>Fpz_08</th>\n",
       "      <th>Fpz_09</th>\n",
       "      <th>...</th>\n",
       "      <th>Fpz_91</th>\n",
       "      <th>Fpz_92</th>\n",
       "      <th>Fpz_93</th>\n",
       "      <th>Fpz_94</th>\n",
       "      <th>Fpz_95</th>\n",
       "      <th>Fpz_96</th>\n",
       "      <th>Fpz_97</th>\n",
       "      <th>Fpz_98</th>\n",
       "      <th>Fpz_99</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:16:35.221257</th>\n",
       "      <td>-2.009272</td>\n",
       "      <td>-2.830380</td>\n",
       "      <td>0.678026</td>\n",
       "      <td>3.171745</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-1.959629</td>\n",
       "      <td>-0.344298</td>\n",
       "      <td>-0.569524</td>\n",
       "      <td>-0.715359</td>\n",
       "      <td>1.636246</td>\n",
       "      <td>...</td>\n",
       "      <td>4.751460</td>\n",
       "      <td>5.493750</td>\n",
       "      <td>5.991572</td>\n",
       "      <td>4.044888</td>\n",
       "      <td>2.897071</td>\n",
       "      <td>3.491017</td>\n",
       "      <td>4.123820</td>\n",
       "      <td>5.224463</td>\n",
       "      <td>5.655671</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:16:35.231257</th>\n",
       "      <td>-1.542927</td>\n",
       "      <td>-2.009272</td>\n",
       "      <td>-2.830380</td>\n",
       "      <td>0.678026</td>\n",
       "      <td>3.171745</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-1.959629</td>\n",
       "      <td>-0.344298</td>\n",
       "      <td>-0.569524</td>\n",
       "      <td>-0.715359</td>\n",
       "      <td>...</td>\n",
       "      <td>6.356289</td>\n",
       "      <td>4.751460</td>\n",
       "      <td>5.493750</td>\n",
       "      <td>5.991572</td>\n",
       "      <td>4.044888</td>\n",
       "      <td>2.897071</td>\n",
       "      <td>3.491017</td>\n",
       "      <td>4.123820</td>\n",
       "      <td>5.224463</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:16:35.241257</th>\n",
       "      <td>-2.104169</td>\n",
       "      <td>-1.542927</td>\n",
       "      <td>-2.009272</td>\n",
       "      <td>-2.830380</td>\n",
       "      <td>0.678026</td>\n",
       "      <td>3.171745</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-1.959629</td>\n",
       "      <td>-0.344298</td>\n",
       "      <td>-0.569524</td>\n",
       "      <td>...</td>\n",
       "      <td>8.057441</td>\n",
       "      <td>6.356289</td>\n",
       "      <td>4.751460</td>\n",
       "      <td>5.493750</td>\n",
       "      <td>5.991572</td>\n",
       "      <td>4.044888</td>\n",
       "      <td>2.897071</td>\n",
       "      <td>3.491017</td>\n",
       "      <td>4.123820</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:16:35.251257</th>\n",
       "      <td>-3.855607</td>\n",
       "      <td>-2.104169</td>\n",
       "      <td>-1.542927</td>\n",
       "      <td>-2.009272</td>\n",
       "      <td>-2.830380</td>\n",
       "      <td>0.678026</td>\n",
       "      <td>3.171745</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-1.959629</td>\n",
       "      <td>-0.344298</td>\n",
       "      <td>...</td>\n",
       "      <td>6.376958</td>\n",
       "      <td>8.057441</td>\n",
       "      <td>6.356289</td>\n",
       "      <td>4.751460</td>\n",
       "      <td>5.493750</td>\n",
       "      <td>5.991572</td>\n",
       "      <td>4.044888</td>\n",
       "      <td>2.897071</td>\n",
       "      <td>3.491017</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:16:35.261257</th>\n",
       "      <td>-7.218886</td>\n",
       "      <td>-3.855607</td>\n",
       "      <td>-2.104169</td>\n",
       "      <td>-1.542927</td>\n",
       "      <td>-2.009272</td>\n",
       "      <td>-2.830380</td>\n",
       "      <td>0.678026</td>\n",
       "      <td>3.171745</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>-1.959629</td>\n",
       "      <td>...</td>\n",
       "      <td>4.146209</td>\n",
       "      <td>6.376958</td>\n",
       "      <td>8.057441</td>\n",
       "      <td>6.356289</td>\n",
       "      <td>4.751460</td>\n",
       "      <td>5.493750</td>\n",
       "      <td>5.991572</td>\n",
       "      <td>4.044888</td>\n",
       "      <td>2.897071</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:17:25.171257</th>\n",
       "      <td>-2.621689</td>\n",
       "      <td>0.963083</td>\n",
       "      <td>-0.513126</td>\n",
       "      <td>-0.069434</td>\n",
       "      <td>2.917220</td>\n",
       "      <td>0.872808</td>\n",
       "      <td>-1.229614</td>\n",
       "      <td>-0.008977</td>\n",
       "      <td>-1.085612</td>\n",
       "      <td>0.344029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879487</td>\n",
       "      <td>1.691575</td>\n",
       "      <td>3.727979</td>\n",
       "      <td>6.287959</td>\n",
       "      <td>0.699076</td>\n",
       "      <td>-4.929825</td>\n",
       "      <td>-1.973310</td>\n",
       "      <td>0.858311</td>\n",
       "      <td>-1.174404</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:17:25.181257</th>\n",
       "      <td>-6.593097</td>\n",
       "      <td>-2.621689</td>\n",
       "      <td>0.963083</td>\n",
       "      <td>-0.513126</td>\n",
       "      <td>-0.069434</td>\n",
       "      <td>2.917220</td>\n",
       "      <td>0.872808</td>\n",
       "      <td>-1.229614</td>\n",
       "      <td>-0.008977</td>\n",
       "      <td>-1.085612</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.808395</td>\n",
       "      <td>0.879487</td>\n",
       "      <td>1.691575</td>\n",
       "      <td>3.727979</td>\n",
       "      <td>6.287959</td>\n",
       "      <td>0.699076</td>\n",
       "      <td>-4.929825</td>\n",
       "      <td>-1.973310</td>\n",
       "      <td>0.858311</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:17:25.191257</th>\n",
       "      <td>-4.372527</td>\n",
       "      <td>-6.593097</td>\n",
       "      <td>-2.621689</td>\n",
       "      <td>0.963083</td>\n",
       "      <td>-0.513126</td>\n",
       "      <td>-0.069434</td>\n",
       "      <td>2.917220</td>\n",
       "      <td>0.872808</td>\n",
       "      <td>-1.229614</td>\n",
       "      <td>-0.008977</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.513772</td>\n",
       "      <td>-3.808395</td>\n",
       "      <td>0.879487</td>\n",
       "      <td>1.691575</td>\n",
       "      <td>3.727979</td>\n",
       "      <td>6.287959</td>\n",
       "      <td>0.699076</td>\n",
       "      <td>-4.929825</td>\n",
       "      <td>-1.973310</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:17:25.201257</th>\n",
       "      <td>-3.217128</td>\n",
       "      <td>-4.372527</td>\n",
       "      <td>-6.593097</td>\n",
       "      <td>-2.621689</td>\n",
       "      <td>0.963083</td>\n",
       "      <td>-0.513126</td>\n",
       "      <td>-0.069434</td>\n",
       "      <td>2.917220</td>\n",
       "      <td>0.872808</td>\n",
       "      <td>-1.229614</td>\n",
       "      <td>...</td>\n",
       "      <td>4.466711</td>\n",
       "      <td>-2.513772</td>\n",
       "      <td>-3.808395</td>\n",
       "      <td>0.879487</td>\n",
       "      <td>1.691575</td>\n",
       "      <td>3.727979</td>\n",
       "      <td>6.287959</td>\n",
       "      <td>0.699076</td>\n",
       "      <td>-4.929825</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 23:17:25.211257</th>\n",
       "      <td>-6.938033</td>\n",
       "      <td>-3.217128</td>\n",
       "      <td>-4.372527</td>\n",
       "      <td>-6.593097</td>\n",
       "      <td>-2.621689</td>\n",
       "      <td>0.963083</td>\n",
       "      <td>-0.513126</td>\n",
       "      <td>-0.069434</td>\n",
       "      <td>2.917220</td>\n",
       "      <td>0.872808</td>\n",
       "      <td>...</td>\n",
       "      <td>3.542382</td>\n",
       "      <td>4.466711</td>\n",
       "      <td>-2.513772</td>\n",
       "      <td>-3.808395</td>\n",
       "      <td>0.879487</td>\n",
       "      <td>1.691575</td>\n",
       "      <td>3.727979</td>\n",
       "      <td>6.287959</td>\n",
       "      <td>0.699076</td>\n",
       "      <td>repos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Fpz    Fpz_01    Fpz_02    Fpz_03    Fpz_04  \\\n",
       "2022-10-29 23:16:35.221257 -2.009272 -2.830380  0.678026  3.171745 -0.076711   \n",
       "2022-10-29 23:16:35.231257 -1.542927 -2.009272 -2.830380  0.678026  3.171745   \n",
       "2022-10-29 23:16:35.241257 -2.104169 -1.542927 -2.009272 -2.830380  0.678026   \n",
       "2022-10-29 23:16:35.251257 -3.855607 -2.104169 -1.542927 -2.009272 -2.830380   \n",
       "2022-10-29 23:16:35.261257 -7.218886 -3.855607 -2.104169 -1.542927 -2.009272   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "2022-10-29 23:17:25.171257 -2.621689  0.963083 -0.513126 -0.069434  2.917220   \n",
       "2022-10-29 23:17:25.181257 -6.593097 -2.621689  0.963083 -0.513126 -0.069434   \n",
       "2022-10-29 23:17:25.191257 -4.372527 -6.593097 -2.621689  0.963083 -0.513126   \n",
       "2022-10-29 23:17:25.201257 -3.217128 -4.372527 -6.593097 -2.621689  0.963083   \n",
       "2022-10-29 23:17:25.211257 -6.938033 -3.217128 -4.372527 -6.593097 -2.621689   \n",
       "\n",
       "                              Fpz_05    Fpz_06    Fpz_07    Fpz_08    Fpz_09  \\\n",
       "2022-10-29 23:16:35.221257 -1.959629 -0.344298 -0.569524 -0.715359  1.636246   \n",
       "2022-10-29 23:16:35.231257 -0.076711 -1.959629 -0.344298 -0.569524 -0.715359   \n",
       "2022-10-29 23:16:35.241257  3.171745 -0.076711 -1.959629 -0.344298 -0.569524   \n",
       "2022-10-29 23:16:35.251257  0.678026  3.171745 -0.076711 -1.959629 -0.344298   \n",
       "2022-10-29 23:16:35.261257 -2.830380  0.678026  3.171745 -0.076711 -1.959629   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "2022-10-29 23:17:25.171257  0.872808 -1.229614 -0.008977 -1.085612  0.344029   \n",
       "2022-10-29 23:17:25.181257  2.917220  0.872808 -1.229614 -0.008977 -1.085612   \n",
       "2022-10-29 23:17:25.191257 -0.069434  2.917220  0.872808 -1.229614 -0.008977   \n",
       "2022-10-29 23:17:25.201257 -0.513126 -0.069434  2.917220  0.872808 -1.229614   \n",
       "2022-10-29 23:17:25.211257  0.963083 -0.513126 -0.069434  2.917220  0.872808   \n",
       "\n",
       "                            ...    Fpz_91    Fpz_92    Fpz_93    Fpz_94  \\\n",
       "2022-10-29 23:16:35.221257  ...  4.751460  5.493750  5.991572  4.044888   \n",
       "2022-10-29 23:16:35.231257  ...  6.356289  4.751460  5.493750  5.991572   \n",
       "2022-10-29 23:16:35.241257  ...  8.057441  6.356289  4.751460  5.493750   \n",
       "2022-10-29 23:16:35.251257  ...  6.376958  8.057441  6.356289  4.751460   \n",
       "2022-10-29 23:16:35.261257  ...  4.146209  6.376958  8.057441  6.356289   \n",
       "...                         ...       ...       ...       ...       ...   \n",
       "2022-10-29 23:17:25.171257  ...  0.879487  1.691575  3.727979  6.287959   \n",
       "2022-10-29 23:17:25.181257  ... -3.808395  0.879487  1.691575  3.727979   \n",
       "2022-10-29 23:17:25.191257  ... -2.513772 -3.808395  0.879487  1.691575   \n",
       "2022-10-29 23:17:25.201257  ...  4.466711 -2.513772 -3.808395  0.879487   \n",
       "2022-10-29 23:17:25.211257  ...  3.542382  4.466711 -2.513772 -3.808395   \n",
       "\n",
       "                              Fpz_95    Fpz_96    Fpz_97    Fpz_98    Fpz_99  \\\n",
       "2022-10-29 23:16:35.221257  2.897071  3.491017  4.123820  5.224463  5.655671   \n",
       "2022-10-29 23:16:35.231257  4.044888  2.897071  3.491017  4.123820  5.224463   \n",
       "2022-10-29 23:16:35.241257  5.991572  4.044888  2.897071  3.491017  4.123820   \n",
       "2022-10-29 23:16:35.251257  5.493750  5.991572  4.044888  2.897071  3.491017   \n",
       "2022-10-29 23:16:35.261257  4.751460  5.493750  5.991572  4.044888  2.897071   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "2022-10-29 23:17:25.171257  0.699076 -4.929825 -1.973310  0.858311 -1.174404   \n",
       "2022-10-29 23:17:25.181257  6.287959  0.699076 -4.929825 -1.973310  0.858311   \n",
       "2022-10-29 23:17:25.191257  3.727979  6.287959  0.699076 -4.929825 -1.973310   \n",
       "2022-10-29 23:17:25.201257  1.691575  3.727979  6.287959  0.699076 -4.929825   \n",
       "2022-10-29 23:17:25.211257  0.879487  1.691575  3.727979  6.287959  0.699076   \n",
       "\n",
       "                            class  \n",
       "2022-10-29 23:16:35.221257  repos  \n",
       "2022-10-29 23:16:35.231257  repos  \n",
       "2022-10-29 23:16:35.241257  repos  \n",
       "2022-10-29 23:16:35.251257  repos  \n",
       "2022-10-29 23:16:35.261257  repos  \n",
       "...                           ...  \n",
       "2022-10-29 23:17:25.171257  repos  \n",
       "2022-10-29 23:17:25.181257  repos  \n",
       "2022-10-29 23:17:25.191257  repos  \n",
       "2022-10-29 23:17:25.201257  repos  \n",
       "2022-10-29 23:17:25.211257  repos  \n",
       "\n",
       "[100000 rows x 101 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.715\n",
    "train_split = int(split_fraction * int(final_df.shape[0]))\n",
    "step = 100\n",
    "\n",
    "past = 1000\n",
    "future = 300\n",
    "learning_rate = 0.001\n",
    "batch_size = 1500\n",
    "epochs = 10\n",
    "\n",
    "start = past + future\n",
    "end = start + train_split\n",
    "\n",
    "\n",
    "def normalize(data, train_split):\n",
    "    data_mean = data[:train_split].mean(axis=0)\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "    return (data - data_mean) / data_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ds():\n",
    "    feature_keys = final_df.columns\n",
    "    print(feature_keys)\n",
    "    selected_features = [feature_keys[i] for i in range(len(feature_keys))]\n",
    "    features = final_df[selected_features]\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    features['class'] = le.fit_transform(features['class'])\n",
    "    \n",
    "    # features.index = final_df['class']\n",
    "    # display(features.head())\n",
    "    \n",
    "    features = normalize(features.values, train_split)\n",
    "    features = pd.DataFrame(features)\n",
    "    features[features.columns[-1]] = le.fit_transform(final_df['class'])\n",
    "    # display(features.head())\n",
    "\n",
    "    train_data = features.loc[0 : train_split - 1]\n",
    "    val_data = features.loc[train_split:]\n",
    "\n",
    "\n",
    "    start = past + future\n",
    "    end = start + train_split\n",
    "\n",
    "    x_train = train_data[[i for i in range(len(feature_keys) - 1)]].values\n",
    "    y_train = features.iloc[start:end][features.columns[-1]]\n",
    "\n",
    "    sequence_length = int(past / step)\n",
    "\n",
    "    dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        sequence_length=sequence_length,\n",
    "        sampling_rate=step,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    sequence_length = int(past / step)\n",
    "\n",
    "\n",
    "    x_end = len(val_data) - past - future\n",
    "    label_start = train_split + past + future\n",
    "    x_val = val_data.iloc[:x_end][[i for i in range(len(feature_keys) - 1)]].values\n",
    "    y_val = features.iloc[label_start:][features.columns[-1]]\n",
    "    # display(x_val.shape)\n",
    "    dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,)\n",
    "    return dataset_train, dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Fpz', 'Fpz_01', 'Fpz_02', 'Fpz_03', 'Fpz_04', 'Fpz_05', 'Fpz_06',\n",
      "       'Fpz_07', 'Fpz_08', 'Fpz_09',\n",
      "       ...\n",
      "       'Fpz_91', 'Fpz_92', 'Fpz_93', 'Fpz_94', 'Fpz_95', 'Fpz_96', 'Fpz_97',\n",
      "       'Fpz_98', 'Fpz_99', 'class'],\n",
      "      dtype='object', length=101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 11:12:43.543448: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1500, 10, 100)\n",
      "Target shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_val = load_ds()\n",
    "\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 100)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 2, 16)             192016    \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 2, 16)             0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1, 16)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1, 32)             1568      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1, 32)             0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 1, 80)             7760      \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 1, 80)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 1, 80)             19280     \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 1, 80)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 1, 80)             19280     \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 1, 80)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 1, 80)             19280     \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 1, 80)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 1, 80)             19280     \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 1, 80)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 1, 80)             19280     \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 1, 80)             0         \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 1, 80)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1, 128)            107008    \n",
      "                                                                 \n",
      " re_lu_8 (ReLU)              (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " re_lu_9 (ReLU)              (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 1, 128)            131584    \n",
      "                                                                 \n",
      " re_lu_10 (ReLU)             (None, 1, 128)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 3)              387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 668,307\n",
      "Trainable params: 668,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 18s 237ms/step - loss: 1.0981 - accuracy: 0.4071 - val_loss: 1.0968 - val_accuracy: 0.3340\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 10s 210ms/step - loss: 1.0952 - accuracy: 0.4071 - val_loss: 1.0958 - val_accuracy: 0.3340\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 10s 218ms/step - loss: 1.0930 - accuracy: 0.4071 - val_loss: 1.0949 - val_accuracy: 0.3340\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 19s 406ms/step - loss: 1.0907 - accuracy: 0.4071 - val_loss: 1.0942 - val_accuracy: 0.3340\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 11s 238ms/step - loss: 1.0898 - accuracy: 0.4071 - val_loss: 1.0941 - val_accuracy: 0.3340\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 11s 222ms/step - loss: 1.0878 - accuracy: 0.4071 - val_loss: 1.0938 - val_accuracy: 0.3340\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 1.0855 - accuracy: 0.4071 - val_loss: 1.0937 - val_accuracy: 0.3340\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 10s 211ms/step - loss: 1.0841 - accuracy: 0.4071 - val_loss: 1.0938 - val_accuracy: 0.3340\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 10s 214ms/step - loss: 1.0830 - accuracy: 0.4071 - val_loss: 1.0940 - val_accuracy: 0.3340\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 11s 227ms/step - loss: 1.0820 - accuracy: 0.4071 - val_loss: 1.0960 - val_accuracy: 0.3340\n"
     ]
    }
   ],
   "source": [
    "m = run_model(dataset_train, dataset_val, inputs, num_classes=3, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9ed0ad7719f06f089edc3238a8d86e962d4ca50119a2518cf9af3ef9ae01f6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
